{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IDL-Baseline-Class_Weights",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1LFufV4clBybUWiTQI5vccWw2owpZjlD7",
      "authorship_tag": "ABX9TyPHhbSTfH177vEcLuLgdPOj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RevanthBN/COVID-GANs/blob/main/IDL_Baseline_Class_Weights.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hbe89wEjrjSE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c763ca06-7b50-44b7-b657-3aa2b8223ae5"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy as sp\n",
        "from matplotlib.pyplot import *\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils import data\n",
        "from torchvision import transforms\n",
        "from torchvision import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error, log_loss\n",
        "from functools import partial\n",
        "from dataclasses import dataclass\n",
        "from collections import OrderedDict\n",
        "import os\n",
        "from PIL import Image\n",
        "import torchvision.transforms.functional as TF\n",
        "import time\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.metrics import roc_auc_score\n",
        "cuda = torch.cuda.is_available()\n",
        "cuda\n",
        "from collections import Counter\n",
        "! pip install torchsummary\n",
        "from torchsummary import summary"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.6/dist-packages (1.5.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylnz1N42b2De"
      },
      "source": [
        "\n",
        "# ! cp /content/drive/MyDrive/kaggle.json ~/.kaggle/\n",
        "# ! chmod 600 ~/.kaggle/kaggle.json\n",
        "# ! kaggle datasets list\n",
        "# ! pip install --upgrade --force-reinstall --no-deps kaggle\n",
        "# # ! kaggle competitions download -c yash612/covidnet-mini-and-gan-enerated-chest-xray\n",
        "# ! kaggle datasets download -d yash612/covidnet-mini-and-gan-enerated-chest-xray\n",
        "# ! unzip covidnet-mini-and-gan-enerated-chest-xray.zip -d data"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmHACDY8KDQA"
      },
      "source": [
        "**Apply transformation on the images**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_oKKuubJ-Ub"
      },
      "source": [
        "trans_apply=transforms.Compose([transforms.Resize((64,64)),transforms.ToTensor()])"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5w530ygAE240"
      },
      "source": [
        "train_dataset=datasets.ImageFolder('/content/drive/MyDrive/data/chest_xray/chest_xray/train',transform=trans_apply)\n",
        "val_dataset=datasets.ImageFolder('/content/drive/MyDrive/data/chest_xray/chest_xray/val',transform=trans_apply)\n",
        "test_dataset=datasets.ImageFolder('/content/drive/MyDrive/data/chest_xray/chest_xray/test',transform=trans_apply)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XIt1hxVIOzD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "outputId": "913de2f2-c6ca-4042-c860-46d3be6c0019"
      },
      "source": [
        "plt.imshow(np.transpose(test_dataset[100][0],axes=(1,2,0)))\n",
        "print(train_dataset[1600][0].shape)\n",
        "print(len(train_dataset.classes))\n",
        "n_classes=len(train_dataset.classes)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 64, 64])\n",
            "3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFRPpmA5IW9L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f599a82c-82b0-4a5a-9da2-dca41cdd5fcc"
      },
      "source": [
        "print(\"train\",train_dataset.__len__(), len(train_dataset.classes))\n",
        "print(\"val\",val_dataset.__len__(), len(val_dataset.classes))\n",
        "print(\"test\",test_dataset.__len__(), len(test_dataset.classes))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train 6862 3\n",
            "val 27 3\n",
            "test 635 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kSvvl1AIodg"
      },
      "source": [
        "num_workers = 12 if cuda else 0 \n",
        "    \n",
        "# Training data\n",
        "train_loader_args = dict(shuffle=True, batch_size=100, num_workers=num_workers) if cuda\\\n",
        "                    else dict(shuffle=True, batch_size=800)\n",
        "train_loader = data.DataLoader(train_dataset, **train_loader_args)\n",
        "\n",
        "# Validation data\n",
        "val_loader_args = dict(shuffle=True, batch_size=10, num_workers=num_workers) if cuda\\\n",
        "                    else dict(shuffle=True, batch_size=500)\n",
        "val_loader = data.DataLoader(val_dataset, **val_loader_args)\n",
        "\n",
        "# Testing data\n",
        "test_loader_args = dict(shuffle=False, num_workers=num_workers) if cuda\\\n",
        "                    else dict(shuffle=False,drop_last=True)\n",
        "test_loader = data.DataLoader(test_dataset, **test_loader_args)\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0c2Syl-NcTgb",
        "outputId": "5311e88e-bef1-41b1-dbc0-7e1017dfe71f"
      },
      "source": [
        "counts=np.zeros(3)\n",
        "for i in range(3):\n",
        "  for sample in train_dataset.samples:\n",
        "    if sample[1]==i:\n",
        "      counts[i]+=1\n",
        "print(counts)\n",
        "weights=torch.FloatTensor(1/counts).cuda()\n",
        "print(weights)\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 950. 1821. 4091.]\n",
            "tensor([0.0011, 0.0005, 0.0002], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1NHmcJqbYav"
      },
      "source": [
        "class Conv2dAuto(nn.Conv2d):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.padding =  (self.kernel_size[0] // 2, self.kernel_size[1] // 2) # dynamic add padding based on the kernel_size\n",
        "        \n",
        "conv3x3 = partial(Conv2dAuto, kernel_size=3, bias=False) \n",
        "\n",
        "def activation_func(activation):\n",
        "    return  nn.ModuleDict([\n",
        "        ['relu', nn.ReLU(inplace=True)],\n",
        "        ['leaky_relu', nn.LeakyReLU(negative_slope=0.01, inplace=True)],\n",
        "        ['selu', nn.SELU(inplace=True)],\n",
        "        ['none', nn.Identity()]\n",
        "    ])[activation]\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, activation='relu'):\n",
        "        super().__init__()\n",
        "        self.in_channels, self.out_channels, self.activation = in_channels, out_channels, activation\n",
        "        self.blocks = nn.Identity()\n",
        "        self.activate = activation_func(activation)\n",
        "        self.shortcut = nn.Identity()   \n",
        "    \n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        if self.should_apply_shortcut: residual = self.shortcut(x)\n",
        "        x = self.blocks(x)\n",
        "        x += residual\n",
        "        x = self.activate(x)\n",
        "        return x\n",
        "    \n",
        "    @property\n",
        "    def should_apply_shortcut(self):\n",
        "        return self.in_channels != self.out_channels\n",
        "\n",
        "class ResNetResidualBlock(ResidualBlock):\n",
        "    def __init__(self, in_channels, out_channels, expansion=1, downsampling=1, conv=conv3x3, *args, **kwargs):\n",
        "        super().__init__(in_channels, out_channels, *args, **kwargs)\n",
        "        self.expansion, self.downsampling, self.conv = expansion, downsampling, conv\n",
        "        self.shortcut = nn.Sequential(\n",
        "            nn.Conv2d(self.in_channels, self.expanded_channels, kernel_size=1,\n",
        "                      stride=self.downsampling, bias=False),\n",
        "            nn.BatchNorm2d(self.expanded_channels, momentum=0.9)) if self.should_apply_shortcut else None\n",
        "        \n",
        "        \n",
        "    @property\n",
        "    def expanded_channels(self):\n",
        "        return self.out_channels * self.expansion\n",
        "    \n",
        "    @property\n",
        "    def should_apply_shortcut(self):\n",
        "        return self.in_channels != self.expanded_channels\n",
        "\n",
        "def conv_bn(in_channels, out_channels, conv, *args, **kwargs):\n",
        "    return nn.Sequential(conv(in_channels, out_channels, *args, **kwargs), nn.BatchNorm2d(out_channels,momentum=0.9))\n",
        "\n",
        "class ResNetBasicBlock(ResNetResidualBlock):\n",
        "    \"\"\"\n",
        "    Basic ResNet block composed by two layers of 3x3conv/batchnorm/activation\n",
        "    \"\"\"\n",
        "    expansion = 1\n",
        "    def __init__(self, in_channels, out_channels, *args, **kwargs):\n",
        "        super().__init__(in_channels, out_channels, *args, **kwargs)\n",
        "        self.blocks = nn.Sequential(\n",
        "            conv_bn(self.in_channels, self.out_channels, conv=self.conv, bias=False, stride=self.downsampling),\n",
        "            activation_func(self.activation),\n",
        "            conv_bn(self.out_channels, self.expanded_channels, conv=self.conv, bias=False),\n",
        "        )\n",
        "\n",
        "class ResNetLayer(nn.Module):\n",
        "    \"\"\"\n",
        "    A ResNet layer composed by `n` blocks stacked one after the other\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels, block=ResNetBasicBlock, n=1, *args, **kwargs):\n",
        "        super().__init__()\n",
        "        # 'We perform downsampling directly by convolutional layers that have a stride of 2.'\n",
        "        downsampling = 2 if in_channels != out_channels else 1\n",
        "        self.blocks = nn.Sequential(\n",
        "            block(in_channels , out_channels, *args, **kwargs, downsampling=downsampling),\n",
        "            *[block(out_channels * block.expansion, \n",
        "                    out_channels, downsampling=1, *args, **kwargs) for _ in range(n - 1)]\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.blocks(x)\n",
        "        return x\n",
        "\n",
        "class ResNetEncoder(nn.Module):\n",
        "    \"\"\"\n",
        "    ResNet encoder composed by layers with increasing features.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels=3, blocks_sizes=[64,128,256,512], deepths=[2,2,2,2], \n",
        "                 activation='relu', block=ResNetBasicBlock, *args, **kwargs):\n",
        "        super().__init__()\n",
        "        self.blocks_sizes = blocks_sizes\n",
        "        \n",
        "        self.gate = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, self.blocks_sizes[0], kernel_size=7, stride=2, padding=3, bias=False),\n",
        "            nn.BatchNorm2d(self.blocks_sizes[0]),\n",
        "            activation_func(activation),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        )\n",
        "        \n",
        "        self.in_out_block_sizes = list(zip(blocks_sizes, blocks_sizes[1:]))\n",
        "        self.blocks = nn.ModuleList([ \n",
        "            ResNetLayer(blocks_sizes[0], blocks_sizes[0], n=deepths[0], activation=activation, \n",
        "                        block=block,*args, **kwargs),\n",
        "            *[ResNetLayer(in_channels * block.expansion, \n",
        "                          out_channels, n=n, activation=activation, \n",
        "                          block=block, *args, **kwargs) \n",
        "              for (in_channels, out_channels), n in zip(self.in_out_block_sizes, deepths[1:])]       \n",
        "        ])\n",
        "        \n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.gate(x)\n",
        "        for block in self.blocks:\n",
        "            x = block(x)\n",
        "        return x\n",
        "\n",
        "class ResnetDecoder(nn.Module):\n",
        "    \"\"\"\n",
        "    This class represents the tail of ResNet. It performs a global pooling and maps the output to the\n",
        "    correct class by using a fully connected layer.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_features, n_classes):\n",
        "        super().__init__()\n",
        "        self.avg = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.decoder = nn.Linear(in_features, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.avg(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        embedding=x\n",
        "        x = self.decoder(x)\n",
        "        return x,embedding\n",
        "      \n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    \n",
        "    def __init__(self, in_channels, n_classes, *args, **kwargs):\n",
        "        super().__init__()\n",
        "        self.encoder = ResNetEncoder(in_channels, *args, **kwargs)\n",
        "        self.decoder = ResnetDecoder(self.encoder.blocks[-1].blocks[-1].expanded_channels, n_classes)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x, embedding = self.decoder(x)\n",
        "        return x, embedding"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yf3w16Bcba-G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c3c51eb-4356-4dc8-9cee-3fe766964a40"
      },
      "source": [
        "def resnet18(in_channels, n_classes, block=ResNetBasicBlock, *args, **kwargs):\n",
        "    return ResNet(in_channels, n_classes, block=block, deepths=[2, 2, 2, 2], *args, **kwargs)\n",
        "\n",
        "def resnet34(in_channels, n_classes, block=ResNetBasicBlock, *args, **kwargs):\n",
        "    return ResNet(in_channels, n_classes, block=block, deepths=[3, 4, 6, 3], *args, **kwargs)\n",
        "model18 = resnet18(3, 3)\n",
        "model34 = resnet34(3,3)\n",
        "criterion = nn.CrossEntropyLoss(weight=weights)\n",
        "learningRate = 1e-2\n",
        "weightDecay = 5e-4\n",
        "optimizer = torch.optim.SGD(model34.parameters(), lr=learningRate, weight_decay=weightDecay, momentum=0.9)\n",
        "scheduler=optim.lr_scheduler.ExponentialLR(optimizer,gamma=0.6)\n",
        "model18.to(device)\n",
        "model34.to(device)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (encoder): ResNetEncoder(\n",
              "    (gate): Sequential(\n",
              "      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "      (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    )\n",
              "    (blocks): ModuleList(\n",
              "      (0): ResNetLayer(\n",
              "        (blocks): Sequential(\n",
              "          (0): ResNetBasicBlock(\n",
              "            (blocks): Sequential(\n",
              "              (0): Sequential(\n",
              "                (0): Conv2dAuto(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                (1): BatchNorm2d(64, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "              )\n",
              "              (1): ReLU(inplace=True)\n",
              "              (2): Sequential(\n",
              "                (0): Conv2dAuto(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                (1): BatchNorm2d(64, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "              )\n",
              "            )\n",
              "            (activate): ReLU(inplace=True)\n",
              "            (shortcut): None\n",
              "          )\n",
              "          (1): ResNetBasicBlock(\n",
              "            (blocks): Sequential(\n",
              "              (0): Sequential(\n",
              "                (0): Conv2dAuto(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                (1): BatchNorm2d(64, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "              )\n",
              "              (1): ReLU(inplace=True)\n",
              "              (2): Sequential(\n",
              "                (0): Conv2dAuto(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                (1): BatchNorm2d(64, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "              )\n",
              "            )\n",
              "            (activate): ReLU(inplace=True)\n",
              "            (shortcut): None\n",
              "          )\n",
              "          (2): ResNetBasicBlock(\n",
              "            (blocks): Sequential(\n",
              "              (0): Sequential(\n",
              "                (0): Conv2dAuto(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                (1): BatchNorm2d(64, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "              )\n",
              "              (1): ReLU(inplace=True)\n",
              "              (2): Sequential(\n",
              "                (0): Conv2dAuto(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                (1): BatchNorm2d(64, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "              )\n",
              "            )\n",
              "            (activate): ReLU(inplace=True)\n",
              "            (shortcut): None\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1): ResNetLayer(\n",
              "        (blocks): Sequential(\n",
              "          (0): ResNetBasicBlock(\n",
              "            (blocks): Sequential(\n",
              "              (0): Sequential(\n",
              "                (0): Conv2dAuto(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "                (1): BatchNorm2d(128, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "              )\n",
              "              (1): ReLU(inplace=True)\n",
              "              (2): Sequential(\n",
              "                (0): Conv2dAuto(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                (1): BatchNorm2d(128, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "              )\n",
              "            )\n",
              "            (activate): ReLU(inplace=True)\n",
              "            (shortcut): Sequential(\n",
              "              (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (1): ResNetBasicBlock(\n",
              "            (blocks): Sequential(\n",
              "              (0): Sequential(\n",
              "                (0): Conv2dAuto(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                (1): BatchNorm2d(128, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "              )\n",
              "              (1): ReLU(inplace=True)\n",
              "              (2): Sequential(\n",
              "                (0): Conv2dAuto(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                (1): BatchNorm2d(128, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "              )\n",
              "            )\n",
              "            (activate): ReLU(inplace=True)\n",
              "            (shortcut): None\n",
              "          )\n",
              "          (2): ResNetBasicBlock(\n",
              "            (blocks): Sequential(\n",
              "              (0): Sequential(\n",
              "                (0): Conv2dAuto(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                (1): BatchNorm2d(128, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "              )\n",
              "              (1): ReLU(inplace=True)\n",
              "              (2): Sequential(\n",
              "                (0): Conv2dAuto(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                (1): BatchNorm2d(128, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "              )\n",
              "            )\n",
              "            (activate): ReLU(inplace=True)\n",
              "            (shortcut): None\n",
              "          )\n",
              "          (3): ResNetBasicBlock(\n",
              "            (blocks): Sequential(\n",
              "              (0): Sequential(\n",
              "                (0): Conv2dAuto(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                (1): BatchNorm2d(128, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "              )\n",
              "              (1): ReLU(inplace=True)\n",
              "              (2): Sequential(\n",
              "                (0): Conv2dAuto(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                (1): BatchNorm2d(128, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "              )\n",
              "            )\n",
              "            (activate): ReLU(inplace=True)\n",
              "            (shortcut): None\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (2): ResNetLayer(\n",
              "        (blocks): Sequential(\n",
              "          (0): ResNetBasicBlock(\n",
              "            (blocks): Sequential(\n",
              "              (0): Sequential(\n",
              "                (0): Conv2dAuto(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "                (1): BatchNorm2d(256, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "              )\n",
              "              (1): ReLU(inplace=True)\n",
              "              (2): Sequential(\n",
              "                (0): Conv2dAuto(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                (1): BatchNorm2d(256, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "              )\n",
              "            )\n",
              "            (activate): ReLU(inplace=True)\n",
              "            (shortcut): Sequential(\n",
              "              (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (1): ResNetBasicBlock(\n",
              "            (blocks): Sequential(\n",
              "              (0): Sequential(\n",
              "                (0): Conv2dAuto(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                (1): BatchNorm2d(256, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "              )\n",
              "              (1): ReLU(inplace=True)\n",
              "              (2): Sequential(\n",
              "                (0): Conv2dAuto(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                (1): BatchNorm2d(256, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "              )\n",
              "            )\n",
              "            (activate): ReLU(inplace=True)\n",
              "            (shortcut): None\n",
              "          )\n",
              "          (2): ResNetBasicBlock(\n",
              "            (blocks): Sequential(\n",
              "              (0): Sequential(\n",
              "                (0): Conv2dAuto(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                (1): BatchNorm2d(256, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "              )\n",
              "              (1): ReLU(inplace=True)\n",
              "              (2): Sequential(\n",
              "                (0): Conv2dAuto(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                (1): BatchNorm2d(256, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "              )\n",
              "            )\n",
              "            (activate): ReLU(inplace=True)\n",
              "            (shortcut): None\n",
              "          )\n",
              "          (3): ResNetBasicBlock(\n",
              "            (blocks): Sequential(\n",
              "              (0): Sequential(\n",
              "                (0): Conv2dAuto(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                (1): BatchNorm2d(256, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "              )\n",
              "              (1): ReLU(inplace=True)\n",
              "              (2): Sequential(\n",
              "                (0): Conv2dAuto(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                (1): BatchNorm2d(256, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "              )\n",
              "            )\n",
              "            (activate): ReLU(inplace=True)\n",
              "            (shortcut): None\n",
              "          )\n",
              "          (4): ResNetBasicBlock(\n",
              "            (blocks): Sequential(\n",
              "              (0): Sequential(\n",
              "                (0): Conv2dAuto(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                (1): BatchNorm2d(256, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "              )\n",
              "              (1): ReLU(inplace=True)\n",
              "              (2): Sequential(\n",
              "                (0): Conv2dAuto(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                (1): BatchNorm2d(256, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "              )\n",
              "            )\n",
              "            (activate): ReLU(inplace=True)\n",
              "            (shortcut): None\n",
              "          )\n",
              "          (5): ResNetBasicBlock(\n",
              "            (blocks): Sequential(\n",
              "              (0): Sequential(\n",
              "                (0): Conv2dAuto(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                (1): BatchNorm2d(256, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "              )\n",
              "              (1): ReLU(inplace=True)\n",
              "              (2): Sequential(\n",
              "                (0): Conv2dAuto(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                (1): BatchNorm2d(256, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "              )\n",
              "            )\n",
              "            (activate): ReLU(inplace=True)\n",
              "            (shortcut): None\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (3): ResNetLayer(\n",
              "        (blocks): Sequential(\n",
              "          (0): ResNetBasicBlock(\n",
              "            (blocks): Sequential(\n",
              "              (0): Sequential(\n",
              "                (0): Conv2dAuto(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "                (1): BatchNorm2d(512, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "              )\n",
              "              (1): ReLU(inplace=True)\n",
              "              (2): Sequential(\n",
              "                (0): Conv2dAuto(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                (1): BatchNorm2d(512, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "              )\n",
              "            )\n",
              "            (activate): ReLU(inplace=True)\n",
              "            (shortcut): Sequential(\n",
              "              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (1): ResNetBasicBlock(\n",
              "            (blocks): Sequential(\n",
              "              (0): Sequential(\n",
              "                (0): Conv2dAuto(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                (1): BatchNorm2d(512, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "              )\n",
              "              (1): ReLU(inplace=True)\n",
              "              (2): Sequential(\n",
              "                (0): Conv2dAuto(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                (1): BatchNorm2d(512, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "              )\n",
              "            )\n",
              "            (activate): ReLU(inplace=True)\n",
              "            (shortcut): None\n",
              "          )\n",
              "          (2): ResNetBasicBlock(\n",
              "            (blocks): Sequential(\n",
              "              (0): Sequential(\n",
              "                (0): Conv2dAuto(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                (1): BatchNorm2d(512, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "              )\n",
              "              (1): ReLU(inplace=True)\n",
              "              (2): Sequential(\n",
              "                (0): Conv2dAuto(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                (1): BatchNorm2d(512, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "              )\n",
              "            )\n",
              "            (activate): ReLU(inplace=True)\n",
              "            (shortcut): None\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (decoder): ResnetDecoder(\n",
              "    (avg): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "    (decoder): Linear(in_features=512, out_features=3, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCeuUIkxbdSv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ac7730d-42e4-43b7-dab6-aace9b775289"
      },
      "source": [
        "summary(model18.cuda(), (3, 64, 64))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           9,408\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-4           [-1, 64, 16, 16]               0\n",
            "        Conv2dAuto-5           [-1, 64, 16, 16]          36,864\n",
            "       BatchNorm2d-6           [-1, 64, 16, 16]             128\n",
            "              ReLU-7           [-1, 64, 16, 16]               0\n",
            "        Conv2dAuto-8           [-1, 64, 16, 16]          36,864\n",
            "       BatchNorm2d-9           [-1, 64, 16, 16]             128\n",
            "             ReLU-10           [-1, 64, 16, 16]               0\n",
            " ResNetBasicBlock-11           [-1, 64, 16, 16]               0\n",
            "       Conv2dAuto-12           [-1, 64, 16, 16]          36,864\n",
            "      BatchNorm2d-13           [-1, 64, 16, 16]             128\n",
            "             ReLU-14           [-1, 64, 16, 16]               0\n",
            "       Conv2dAuto-15           [-1, 64, 16, 16]          36,864\n",
            "      BatchNorm2d-16           [-1, 64, 16, 16]             128\n",
            "             ReLU-17           [-1, 64, 16, 16]               0\n",
            " ResNetBasicBlock-18           [-1, 64, 16, 16]               0\n",
            "      ResNetLayer-19           [-1, 64, 16, 16]               0\n",
            "           Conv2d-20            [-1, 128, 8, 8]           8,192\n",
            "      BatchNorm2d-21            [-1, 128, 8, 8]             256\n",
            "       Conv2dAuto-22            [-1, 128, 8, 8]          73,728\n",
            "      BatchNorm2d-23            [-1, 128, 8, 8]             256\n",
            "             ReLU-24            [-1, 128, 8, 8]               0\n",
            "       Conv2dAuto-25            [-1, 128, 8, 8]         147,456\n",
            "      BatchNorm2d-26            [-1, 128, 8, 8]             256\n",
            "             ReLU-27            [-1, 128, 8, 8]               0\n",
            " ResNetBasicBlock-28            [-1, 128, 8, 8]               0\n",
            "       Conv2dAuto-29            [-1, 128, 8, 8]         147,456\n",
            "      BatchNorm2d-30            [-1, 128, 8, 8]             256\n",
            "             ReLU-31            [-1, 128, 8, 8]               0\n",
            "       Conv2dAuto-32            [-1, 128, 8, 8]         147,456\n",
            "      BatchNorm2d-33            [-1, 128, 8, 8]             256\n",
            "             ReLU-34            [-1, 128, 8, 8]               0\n",
            " ResNetBasicBlock-35            [-1, 128, 8, 8]               0\n",
            "      ResNetLayer-36            [-1, 128, 8, 8]               0\n",
            "           Conv2d-37            [-1, 256, 4, 4]          32,768\n",
            "      BatchNorm2d-38            [-1, 256, 4, 4]             512\n",
            "       Conv2dAuto-39            [-1, 256, 4, 4]         294,912\n",
            "      BatchNorm2d-40            [-1, 256, 4, 4]             512\n",
            "             ReLU-41            [-1, 256, 4, 4]               0\n",
            "       Conv2dAuto-42            [-1, 256, 4, 4]         589,824\n",
            "      BatchNorm2d-43            [-1, 256, 4, 4]             512\n",
            "             ReLU-44            [-1, 256, 4, 4]               0\n",
            " ResNetBasicBlock-45            [-1, 256, 4, 4]               0\n",
            "       Conv2dAuto-46            [-1, 256, 4, 4]         589,824\n",
            "      BatchNorm2d-47            [-1, 256, 4, 4]             512\n",
            "             ReLU-48            [-1, 256, 4, 4]               0\n",
            "       Conv2dAuto-49            [-1, 256, 4, 4]         589,824\n",
            "      BatchNorm2d-50            [-1, 256, 4, 4]             512\n",
            "             ReLU-51            [-1, 256, 4, 4]               0\n",
            " ResNetBasicBlock-52            [-1, 256, 4, 4]               0\n",
            "      ResNetLayer-53            [-1, 256, 4, 4]               0\n",
            "           Conv2d-54            [-1, 512, 2, 2]         131,072\n",
            "      BatchNorm2d-55            [-1, 512, 2, 2]           1,024\n",
            "       Conv2dAuto-56            [-1, 512, 2, 2]       1,179,648\n",
            "      BatchNorm2d-57            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-58            [-1, 512, 2, 2]               0\n",
            "       Conv2dAuto-59            [-1, 512, 2, 2]       2,359,296\n",
            "      BatchNorm2d-60            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-61            [-1, 512, 2, 2]               0\n",
            " ResNetBasicBlock-62            [-1, 512, 2, 2]               0\n",
            "       Conv2dAuto-63            [-1, 512, 2, 2]       2,359,296\n",
            "      BatchNorm2d-64            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-65            [-1, 512, 2, 2]               0\n",
            "       Conv2dAuto-66            [-1, 512, 2, 2]       2,359,296\n",
            "      BatchNorm2d-67            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-68            [-1, 512, 2, 2]               0\n",
            " ResNetBasicBlock-69            [-1, 512, 2, 2]               0\n",
            "      ResNetLayer-70            [-1, 512, 2, 2]               0\n",
            "    ResNetEncoder-71            [-1, 512, 2, 2]               0\n",
            "AdaptiveAvgPool2d-72            [-1, 512, 1, 1]               0\n",
            "           Linear-73                    [-1, 3]           1,539\n",
            "    ResnetDecoder-74       [[-1, 3], [-1, 512]]               0\n",
            "================================================================\n",
            "Total params: 11,178,051\n",
            "Trainable params: 11,178,051\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.05\n",
            "Forward/backward pass size (MB): 5.37\n",
            "Params size (MB): 42.64\n",
            "Estimated Total Size (MB): 48.05\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXwejTJvTuaT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f98cc7fd-a968-4e9b-d12b-ffb6b62893d1"
      },
      "source": [
        "summary(model34.cuda(), (3, 64, 64))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           9,408\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-4           [-1, 64, 16, 16]               0\n",
            "        Conv2dAuto-5           [-1, 64, 16, 16]          36,864\n",
            "       BatchNorm2d-6           [-1, 64, 16, 16]             128\n",
            "              ReLU-7           [-1, 64, 16, 16]               0\n",
            "        Conv2dAuto-8           [-1, 64, 16, 16]          36,864\n",
            "       BatchNorm2d-9           [-1, 64, 16, 16]             128\n",
            "             ReLU-10           [-1, 64, 16, 16]               0\n",
            " ResNetBasicBlock-11           [-1, 64, 16, 16]               0\n",
            "       Conv2dAuto-12           [-1, 64, 16, 16]          36,864\n",
            "      BatchNorm2d-13           [-1, 64, 16, 16]             128\n",
            "             ReLU-14           [-1, 64, 16, 16]               0\n",
            "       Conv2dAuto-15           [-1, 64, 16, 16]          36,864\n",
            "      BatchNorm2d-16           [-1, 64, 16, 16]             128\n",
            "             ReLU-17           [-1, 64, 16, 16]               0\n",
            " ResNetBasicBlock-18           [-1, 64, 16, 16]               0\n",
            "       Conv2dAuto-19           [-1, 64, 16, 16]          36,864\n",
            "      BatchNorm2d-20           [-1, 64, 16, 16]             128\n",
            "             ReLU-21           [-1, 64, 16, 16]               0\n",
            "       Conv2dAuto-22           [-1, 64, 16, 16]          36,864\n",
            "      BatchNorm2d-23           [-1, 64, 16, 16]             128\n",
            "             ReLU-24           [-1, 64, 16, 16]               0\n",
            " ResNetBasicBlock-25           [-1, 64, 16, 16]               0\n",
            "      ResNetLayer-26           [-1, 64, 16, 16]               0\n",
            "           Conv2d-27            [-1, 128, 8, 8]           8,192\n",
            "      BatchNorm2d-28            [-1, 128, 8, 8]             256\n",
            "       Conv2dAuto-29            [-1, 128, 8, 8]          73,728\n",
            "      BatchNorm2d-30            [-1, 128, 8, 8]             256\n",
            "             ReLU-31            [-1, 128, 8, 8]               0\n",
            "       Conv2dAuto-32            [-1, 128, 8, 8]         147,456\n",
            "      BatchNorm2d-33            [-1, 128, 8, 8]             256\n",
            "             ReLU-34            [-1, 128, 8, 8]               0\n",
            " ResNetBasicBlock-35            [-1, 128, 8, 8]               0\n",
            "       Conv2dAuto-36            [-1, 128, 8, 8]         147,456\n",
            "      BatchNorm2d-37            [-1, 128, 8, 8]             256\n",
            "             ReLU-38            [-1, 128, 8, 8]               0\n",
            "       Conv2dAuto-39            [-1, 128, 8, 8]         147,456\n",
            "      BatchNorm2d-40            [-1, 128, 8, 8]             256\n",
            "             ReLU-41            [-1, 128, 8, 8]               0\n",
            " ResNetBasicBlock-42            [-1, 128, 8, 8]               0\n",
            "       Conv2dAuto-43            [-1, 128, 8, 8]         147,456\n",
            "      BatchNorm2d-44            [-1, 128, 8, 8]             256\n",
            "             ReLU-45            [-1, 128, 8, 8]               0\n",
            "       Conv2dAuto-46            [-1, 128, 8, 8]         147,456\n",
            "      BatchNorm2d-47            [-1, 128, 8, 8]             256\n",
            "             ReLU-48            [-1, 128, 8, 8]               0\n",
            " ResNetBasicBlock-49            [-1, 128, 8, 8]               0\n",
            "       Conv2dAuto-50            [-1, 128, 8, 8]         147,456\n",
            "      BatchNorm2d-51            [-1, 128, 8, 8]             256\n",
            "             ReLU-52            [-1, 128, 8, 8]               0\n",
            "       Conv2dAuto-53            [-1, 128, 8, 8]         147,456\n",
            "      BatchNorm2d-54            [-1, 128, 8, 8]             256\n",
            "             ReLU-55            [-1, 128, 8, 8]               0\n",
            " ResNetBasicBlock-56            [-1, 128, 8, 8]               0\n",
            "      ResNetLayer-57            [-1, 128, 8, 8]               0\n",
            "           Conv2d-58            [-1, 256, 4, 4]          32,768\n",
            "      BatchNorm2d-59            [-1, 256, 4, 4]             512\n",
            "       Conv2dAuto-60            [-1, 256, 4, 4]         294,912\n",
            "      BatchNorm2d-61            [-1, 256, 4, 4]             512\n",
            "             ReLU-62            [-1, 256, 4, 4]               0\n",
            "       Conv2dAuto-63            [-1, 256, 4, 4]         589,824\n",
            "      BatchNorm2d-64            [-1, 256, 4, 4]             512\n",
            "             ReLU-65            [-1, 256, 4, 4]               0\n",
            " ResNetBasicBlock-66            [-1, 256, 4, 4]               0\n",
            "       Conv2dAuto-67            [-1, 256, 4, 4]         589,824\n",
            "      BatchNorm2d-68            [-1, 256, 4, 4]             512\n",
            "             ReLU-69            [-1, 256, 4, 4]               0\n",
            "       Conv2dAuto-70            [-1, 256, 4, 4]         589,824\n",
            "      BatchNorm2d-71            [-1, 256, 4, 4]             512\n",
            "             ReLU-72            [-1, 256, 4, 4]               0\n",
            " ResNetBasicBlock-73            [-1, 256, 4, 4]               0\n",
            "       Conv2dAuto-74            [-1, 256, 4, 4]         589,824\n",
            "      BatchNorm2d-75            [-1, 256, 4, 4]             512\n",
            "             ReLU-76            [-1, 256, 4, 4]               0\n",
            "       Conv2dAuto-77            [-1, 256, 4, 4]         589,824\n",
            "      BatchNorm2d-78            [-1, 256, 4, 4]             512\n",
            "             ReLU-79            [-1, 256, 4, 4]               0\n",
            " ResNetBasicBlock-80            [-1, 256, 4, 4]               0\n",
            "       Conv2dAuto-81            [-1, 256, 4, 4]         589,824\n",
            "      BatchNorm2d-82            [-1, 256, 4, 4]             512\n",
            "             ReLU-83            [-1, 256, 4, 4]               0\n",
            "       Conv2dAuto-84            [-1, 256, 4, 4]         589,824\n",
            "      BatchNorm2d-85            [-1, 256, 4, 4]             512\n",
            "             ReLU-86            [-1, 256, 4, 4]               0\n",
            " ResNetBasicBlock-87            [-1, 256, 4, 4]               0\n",
            "       Conv2dAuto-88            [-1, 256, 4, 4]         589,824\n",
            "      BatchNorm2d-89            [-1, 256, 4, 4]             512\n",
            "             ReLU-90            [-1, 256, 4, 4]               0\n",
            "       Conv2dAuto-91            [-1, 256, 4, 4]         589,824\n",
            "      BatchNorm2d-92            [-1, 256, 4, 4]             512\n",
            "             ReLU-93            [-1, 256, 4, 4]               0\n",
            " ResNetBasicBlock-94            [-1, 256, 4, 4]               0\n",
            "       Conv2dAuto-95            [-1, 256, 4, 4]         589,824\n",
            "      BatchNorm2d-96            [-1, 256, 4, 4]             512\n",
            "             ReLU-97            [-1, 256, 4, 4]               0\n",
            "       Conv2dAuto-98            [-1, 256, 4, 4]         589,824\n",
            "      BatchNorm2d-99            [-1, 256, 4, 4]             512\n",
            "            ReLU-100            [-1, 256, 4, 4]               0\n",
            "ResNetBasicBlock-101            [-1, 256, 4, 4]               0\n",
            "     ResNetLayer-102            [-1, 256, 4, 4]               0\n",
            "          Conv2d-103            [-1, 512, 2, 2]         131,072\n",
            "     BatchNorm2d-104            [-1, 512, 2, 2]           1,024\n",
            "      Conv2dAuto-105            [-1, 512, 2, 2]       1,179,648\n",
            "     BatchNorm2d-106            [-1, 512, 2, 2]           1,024\n",
            "            ReLU-107            [-1, 512, 2, 2]               0\n",
            "      Conv2dAuto-108            [-1, 512, 2, 2]       2,359,296\n",
            "     BatchNorm2d-109            [-1, 512, 2, 2]           1,024\n",
            "            ReLU-110            [-1, 512, 2, 2]               0\n",
            "ResNetBasicBlock-111            [-1, 512, 2, 2]               0\n",
            "      Conv2dAuto-112            [-1, 512, 2, 2]       2,359,296\n",
            "     BatchNorm2d-113            [-1, 512, 2, 2]           1,024\n",
            "            ReLU-114            [-1, 512, 2, 2]               0\n",
            "      Conv2dAuto-115            [-1, 512, 2, 2]       2,359,296\n",
            "     BatchNorm2d-116            [-1, 512, 2, 2]           1,024\n",
            "            ReLU-117            [-1, 512, 2, 2]               0\n",
            "ResNetBasicBlock-118            [-1, 512, 2, 2]               0\n",
            "      Conv2dAuto-119            [-1, 512, 2, 2]       2,359,296\n",
            "     BatchNorm2d-120            [-1, 512, 2, 2]           1,024\n",
            "            ReLU-121            [-1, 512, 2, 2]               0\n",
            "      Conv2dAuto-122            [-1, 512, 2, 2]       2,359,296\n",
            "     BatchNorm2d-123            [-1, 512, 2, 2]           1,024\n",
            "            ReLU-124            [-1, 512, 2, 2]               0\n",
            "ResNetBasicBlock-125            [-1, 512, 2, 2]               0\n",
            "     ResNetLayer-126            [-1, 512, 2, 2]               0\n",
            "   ResNetEncoder-127            [-1, 512, 2, 2]               0\n",
            "AdaptiveAvgPool2d-128            [-1, 512, 1, 1]               0\n",
            "          Linear-129                    [-1, 3]           1,539\n",
            "   ResnetDecoder-130       [[-1, 3], [-1, 512]]               0\n",
            "================================================================\n",
            "Total params: 21,286,211\n",
            "Trainable params: 21,286,211\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.05\n",
            "Forward/backward pass size (MB): 8.10\n",
            "Params size (MB): 81.20\n",
            "Estimated Total Size (MB): 89.35\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KMG0BBdbyEE"
      },
      "source": [
        "def train_epoch(model, train_loader, criterion, optimizer):\n",
        "    model.train()\n",
        "    model.cuda()\n",
        "    criterion.cuda()\n",
        "    running_loss = 0.0\n",
        "    print(\"Entered Training\")\n",
        "    start_time = time.time()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):   \n",
        "        optimizer.zero_grad()   # .backward() accumulates gradients\n",
        "        data = data.cuda()\n",
        "        target = target.cuda() # all data & model on same device\n",
        "\n",
        "        outputs,embeddings = model(data)\n",
        "        loss = criterion(outputs, target)\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    end_time = time.time()\n",
        "    \n",
        "    running_loss /= len(train_loader)\n",
        "    print('Training Loss: ', running_loss, 'Time: ',end_time - start_time, 's')\n",
        "    return running_loss\n",
        "\n",
        "def test_model(model, val_loader, criterion):\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        print(\"Entered Evaluation\")\n",
        "        running_loss = 0.0\n",
        "        total_predictions = 0.0\n",
        "        correct_predictions = 0.0\n",
        "        model.cuda()\n",
        "        criterion.cuda()\n",
        "        for batch_idx, (data, target) in enumerate(val_loader):   \n",
        "            data = data.cuda()\n",
        "            target = target.cuda()\n",
        "\n",
        "            outputs,embeddings = model(data)\n",
        "\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total_predictions += target.size(0)\n",
        "            correct_predictions += (predicted == target).sum().item()\n",
        "\n",
        "            loss = criterion(outputs, target).detach()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "\n",
        "        running_loss /= len(val_loader)\n",
        "        acc = (correct_predictions/total_predictions)*100.0\n",
        "        print('Val Loss: ', running_loss)\n",
        "        print('Val Accuracy: ', acc, '%')\n",
        "        return running_loss, acc\n"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jo5FSxlBcAkk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4b8444c-1bb5-47c3-9ba9-c18a6472d244"
      },
      "source": [
        "n_epochs = 15\n",
        "Train_loss = []\n",
        "Test_loss = []\n",
        "Test_acc = []\n",
        "\n",
        "for i in range(n_epochs):\n",
        "    print(\"Epoch Number -- \",i+1)\n",
        "    train_loss = train_epoch(model34, train_loader, criterion, optimizer)\n",
        "    test_loss, test_acc = test_model(model34, val_loader, criterion)\n",
        "    # auc=test_verify(model,ver_loader)\n",
        "    Train_loss.append(train_loss)\n",
        "    Test_loss.append(test_loss)\n",
        "    Test_acc.append(test_acc)\n",
        "    scheduler.step()\n",
        "    print('='*20)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch Number --  1\n",
            "Entered Training\n",
            "Training Loss:  0.5799405013305553 Time:  164.34496402740479 s\n",
            "Entered Evaluation\n",
            "Val Loss:  0.2825180987517039\n",
            "Val Accuracy:  85.18518518518519 %\n",
            "====================\n",
            "Epoch Number --  2\n",
            "Entered Training\n",
            "Training Loss:  0.1878215228949768 Time:  45.48534274101257 s\n",
            "Entered Evaluation\n",
            "Val Loss:  0.3781386464834213\n",
            "Val Accuracy:  81.48148148148148 %\n",
            "====================\n",
            "Epoch Number --  3\n",
            "Entered Training\n",
            "Training Loss:  0.1311235672969749 Time:  47.13444209098816 s\n",
            "Entered Evaluation\n",
            "Val Loss:  1.0117991367975872\n",
            "Val Accuracy:  62.96296296296296 %\n",
            "====================\n",
            "Epoch Number --  4\n",
            "Entered Training\n",
            "Training Loss:  0.11237871020600415 Time:  45.38340163230896 s\n",
            "Entered Evaluation\n",
            "Val Loss:  0.4831882913907369\n",
            "Val Accuracy:  77.77777777777779 %\n",
            "====================\n",
            "Epoch Number --  5\n",
            "Entered Training\n",
            "Training Loss:  0.09502125504440155 Time:  45.35195064544678 s\n",
            "Entered Evaluation\n",
            "Val Loss:  0.40623114506403607\n",
            "Val Accuracy:  77.77777777777779 %\n",
            "====================\n",
            "Epoch Number --  6\n",
            "Entered Training\n",
            "Training Loss:  0.08730230847562569 Time:  44.920581102371216 s\n",
            "Entered Evaluation\n",
            "Val Loss:  0.18793682008981705\n",
            "Val Accuracy:  88.88888888888889 %\n",
            "====================\n",
            "Epoch Number --  7\n",
            "Entered Training\n",
            "Training Loss:  0.08543007796549279 Time:  45.05061721801758 s\n",
            "Entered Evaluation\n",
            "Val Loss:  0.5201505472262701\n",
            "Val Accuracy:  81.48148148148148 %\n",
            "====================\n",
            "Epoch Number --  8\n",
            "Entered Training\n",
            "Training Loss:  0.07988518535874892 Time:  45.61917757987976 s\n",
            "Entered Evaluation\n",
            "Val Loss:  0.26807356874148053\n",
            "Val Accuracy:  88.88888888888889 %\n",
            "====================\n",
            "Epoch Number --  9\n",
            "Entered Training\n",
            "Training Loss:  0.0786856443931659 Time:  45.190266609191895 s\n",
            "Entered Evaluation\n",
            "Val Loss:  0.35831913352012634\n",
            "Val Accuracy:  88.88888888888889 %\n",
            "====================\n",
            "Epoch Number --  10\n",
            "Entered Training\n",
            "Training Loss:  0.07342426362784876 Time:  45.40849447250366 s\n",
            "Entered Evaluation\n",
            "Val Loss:  0.33130590120951336\n",
            "Val Accuracy:  88.88888888888889 %\n",
            "====================\n",
            "Epoch Number --  11\n",
            "Entered Training\n",
            "Training Loss:  0.07487948209155297 Time:  45.59880208969116 s\n",
            "Entered Evaluation\n",
            "Val Loss:  0.31879206250111264\n",
            "Val Accuracy:  88.88888888888889 %\n",
            "====================\n",
            "Epoch Number --  12\n",
            "Entered Training\n",
            "Training Loss:  0.07600814187764257 Time:  45.92976927757263 s\n",
            "Entered Evaluation\n",
            "Val Loss:  0.3620860775311788\n",
            "Val Accuracy:  88.88888888888889 %\n",
            "====================\n",
            "Epoch Number --  13\n",
            "Entered Training\n",
            "Training Loss:  0.07315451206396455 Time:  45.82577991485596 s\n",
            "Entered Evaluation\n",
            "Val Loss:  0.30036476751168567\n",
            "Val Accuracy:  88.88888888888889 %\n",
            "====================\n",
            "Epoch Number --  14\n",
            "Entered Training\n",
            "Training Loss:  0.07598675595785397 Time:  45.78280735015869 s\n",
            "Entered Evaluation\n",
            "Val Loss:  0.3241225729386012\n",
            "Val Accuracy:  88.88888888888889 %\n",
            "====================\n",
            "Epoch Number --  15\n",
            "Entered Training\n",
            "Training Loss:  0.07359692108803902 Time:  45.2327778339386 s\n",
            "Entered Evaluation\n",
            "Val Loss:  0.31995919595162076\n",
            "Val Accuracy:  88.88888888888889 %\n",
            "====================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9aXVL83cGmB"
      },
      "source": [
        "def pred(model, test_loader, criterion):\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        print(\"Entered Evaluation\")\n",
        "        running_loss = 0.0\n",
        "        total_predictions = 0.0\n",
        "        correct_predictions = 0.0\n",
        "        model.cuda()\n",
        "        criterion.cuda()\n",
        "        for batch_idx, (data, target) in enumerate(val_loader):   \n",
        "            data = data.cuda()\n",
        "            target = target.cuda()\n",
        "\n",
        "            outputs,embeddings = model(data)\n",
        "\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total_predictions += target.size(0)\n",
        "            correct_predictions += (predicted == target).sum().item()\n",
        "\n",
        "            loss = criterion(outputs, target).detach()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "\n",
        "        running_loss /= len(val_loader)\n",
        "        acc = (correct_predictions/total_predictions)*100.0\n",
        "        print('Testing Loss: ', running_loss)\n",
        "        print('Testing Accuracy: ', acc, '%')\n",
        "        return running_loss, acc"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Tq3zNMBzYpA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7845d740-288a-4084-8173-a78675013342"
      },
      "source": [
        "test_loss, test_acc = pred(model34, test_loader, criterion)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Entered Evaluation\n",
            "Testing Loss:  0.2831299503644307\n",
            "Testing Accuracy:  88.88888888888889 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nXDTP7E0rkT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}